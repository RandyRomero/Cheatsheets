#############################################################
Get number of non-NaN items within a pandas Series
some_series.count()

#############################################################
Get mean values for items in a pandas Series
some_series.mean()

#############################################################
Drop all items from a pandas Series which are less than 100
songs = pd.Series([145 , 142 , 38 , 13], name='counts', index=['Paul', 'John', 'George', 'Ringo'])
songs = songs[songs > 100]

#############################################################
Get size of a pandas Series
some_series.size


##############################################################
print several specific columns:
df[['column_name', 'some_other_column_name"]]


##############################################################
remove values if there is missing cells in specific columns:
data = data.dropna(axis=0, subset=['Дата рождения застрахованного (или возраст)', 'Идентификатор застрахованного'])

##############################################################
count unique values:
df['sex'].value_counts()
male      577
female    314
Name: sex, dtype: int64

##############################################################
count unique values in column:
print(data['ИД услуги'].nunique())

##############################################################
return cell value by cell value in another column in the same row:
config.loc[config['col_rename'] == 'SERVICE_AMOUNT', 'col_name'].values[0]

##############################################################
Count total NaN at each column in DataFrame:
print(df.isnull().sum())

Name       1
Age        3
City       3
Country    2

##############################################################
drop rows where value in a specific column is empty
df = df[pd.notnull(df['name of column'])]

##############################################################
find null values in a specific column
print(pd.isnull(data['AGE']).to_numpy().nonzero()[0])

##############################################################
fill null values with default value in a specific column
data['AGE'] = data['AGE'].fillna(20)

##############################################################
rename columns
data = data.rename(columns={"SERVICE_NAME": "SERVICE_NAME_ENG", "some_other_name": "some_other_rename")

##############################################################
return pd.Series from a dataframe by position:
df.iloc[0] - return the first row

##############################################################
return dataframe from a dataframe by position:
df.iloc[[0]] - return the first row, but as a dataframe

##############################################################
filter out rows by appying a function
new_df = df[df['column_name'].apply(your_function)]

def your_function(value_from_column):
    if something with value: 
        return True
    return False

##############################################################
change value in a column if this value exists in some given sequence

kids = ('Дети от 1 до 17-ти лет', 'Дети от 0 до 1 года',)

new_df.loc[new_df['age'].isin(kids), 'age'] = 'детский'

##############################################################
change value in a column if this value equals something

new_df.loc[new_df['age'] == 'Дети от 1 до 17-ти лет', 'age'] = 'детский'

##############################################################
print list of all column names
list(df)

##############################################################
make a new df out of unique values that occures more than 1 time

df1: pd.DataFrame = data.groupby('INSURED_ID').filter(lambda x: x['INSURED_BIRTHDAY'].nunique() > 1)


##############################################################
remove rows from a df by subtracting from it another df

df1 = df1[~df1.index.isin(df2.index)]

##############################################################
 # single out rows where there is more than one birthday for one insured
    df1 = data.groupby('INSURED_ID').filter(lambda x: x['INSURED_BIRTHDAY'].nunique() > 1)

##############################################################
filter out rows with null values in a specific column
null_brthds = data[~data['INSURED_BIRTHDAY'].notnull()]


##############################################################
drop specific columns
data = data.drop(columns=['INSURED_AGE_WHEN_SERVICED'])

##############################################################
change value where there is another value
data[data['Код диагноза'].str.len() == 1] = ''


##############################################################
make a new df where a value in a special column equals something
broken_mkb = data[data['Код диагноза'].str.len() == 1]


##############################################################
select second column
df.iloc[:, 1]

##############################################################
select first row
df.iloc[0]

##############################################################
df.iloc[:, 4] = df.iloc[:, 4].str.replace('№ ', '', regex=False)

##############################################################
find all rows where some strings in a column contain specific characters
df = df[df.iloc[:, 4].str.contains('№')]

##############################################################
dispaly long strings in a dataframe
pd.set_option('display.max_colwidth', 200)


##############################################################
get one row as a dataframe
df.iloc[[94]]

##############################################################
a |= b means a = a or b

##############################################################
df_old.sort_values(by='Дата услуги', inplace=False)

by several columns
df_old.sort_values(by=['Uniq_id', 'Дата услуги'], inplace=True)

##############################################################
df2 = pd.DataFrame(index=df1.index)